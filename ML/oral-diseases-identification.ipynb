{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10033628,"sourceType":"datasetVersion","datasetId":6179958}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\nimport pickle\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2\nimport zipfile\nimport shutil\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Input\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import Sequential, load_model, Model\nfrom tensorflow.keras.layers import RandomFlip, RandomRotation, RandomZoom, RandomContrast, Rescaling\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.callbacks import EarlyStopping, TensorBoard\nfrom tensorflow.keras.optimizers import Adam\nfrom keras import Input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:22:04.655937Z","iopub.execute_input":"2024-11-30T14:22:04.656561Z","iopub.status.idle":"2024-11-30T14:22:16.610311Z","shell.execute_reply.started":"2024-11-30T14:22:04.656519Z","shell.execute_reply":"2024-11-30T14:22:16.609128Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/oral-diseases/unprocessed'\ncategories = ['calculus', 'caries', 'gingivitis', 'hypodontia', 'tooth_discoloration', 'ulcer']\n\n# Define directories for train, validation, and test splits\nbase_dir = '/kaggle/working/dataset'\ntrain_dir = os.path.join(base_dir, 'train')\nval_dir = os.path.join(base_dir, 'val')\ntest_dir = os.path.join(base_dir, 'test')\n\n# Create the train, validation, and test directories with subdirectories for each category\nfor category in categories:\n    os.makedirs(os.path.join(train_dir, category), exist_ok=True)\n    os.makedirs(os.path.join(val_dir, category), exist_ok=True)\n    os.makedirs(os.path.join(test_dir, category), exist_ok=True)\n\n# Split each category\nfor category in categories:\n    category_dir = os.path.join(DATA_DIR, category)\n    filenames = os.listdir(category_dir)\n    # Split the dataset into train, val, and test sets (e.g., 80% train, 10% validation, 10% test)\n    train_filenames, temp_filenames = train_test_split(filenames, test_size=0.2, random_state=42)\n    val_filenames, test_filenames = train_test_split(temp_filenames, test_size=0.5, random_state=42)\n\n    for filename in train_filenames:\n        shutil.copy(os.path.join(category_dir, filename), os.path.join(train_dir, category, filename))\n    for filename in val_filenames:\n        shutil.copy(os.path.join(category_dir, filename), os.path.join(val_dir, category, filename))\n    for filename in test_filenames:\n        shutil.copy(os.path.join(category_dir, filename), os.path.join(test_dir, category, filename))\n\nprint(\"Data split completed!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:22:59.004779Z","iopub.execute_input":"2024-11-30T14:22:59.005793Z","iopub.status.idle":"2024-11-30T14:23:44.447162Z","shell.execute_reply.started":"2024-11-30T14:22:59.005753Z","shell.execute_reply":"2024-11-30T14:23:44.446284Z"}},"outputs":[{"name":"stdout","text":"Data split completed!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Set parameters\nDIMX, DIMY = 224, 224  # Image dimensions\nHIDDEN = 128           # Number of hidden units in dense layer\nOUTPUT_CLASSES = 6     # Number of output classes\nBATCH_SIZE = 32\nINITIAL_LEARNING_RATE = 0.001\nNUM_FINETUNE_EPOCHS = 10\n\n# Data generators\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    os.path.join(base_dir, \"train\"),\n    target_size=(DIMX, DIMY),\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\"\n)\nval_generator = val_datagen.flow_from_directory(\n    os.path.join(base_dir, \"val\"),\n    target_size=(DIMX, DIMY),\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\"\n)\ntest_generator = test_datagen.flow_from_directory(\n    os.path.join(base_dir, \"test\"),\n    target_size=(DIMX, DIMY),\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:24:02.016504Z","iopub.execute_input":"2024-11-30T14:24:02.016840Z","iopub.status.idle":"2024-11-30T14:24:02.246646Z","shell.execute_reply.started":"2024-11-30T14:24:02.016812Z","shell.execute_reply":"2024-11-30T14:24:02.246046Z"}},"outputs":[{"name":"stdout","text":"Found 9319 images belonging to 6 classes.\nFound 1165 images belonging to 6 classes.\nFound 1169 images belonging to 6 classes.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(\"Classes detected:\", train_generator.class_indices)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:24:06.008580Z","iopub.execute_input":"2024-11-30T14:24:06.009440Z","iopub.status.idle":"2024-11-30T14:24:06.014347Z","shell.execute_reply.started":"2024-11-30T14:24:06.009368Z","shell.execute_reply":"2024-11-30T14:24:06.013458Z"}},"outputs":[{"name":"stdout","text":"Classes detected: {'calculus': 0, 'caries': 1, 'gingivitis': 2, 'hypodontia': 3, 'tooth_discoloration': 4, 'ulcer': 5}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Directories for train, val, and test splits\nsplit_directories = {'train': train_dir, 'val': val_dir, 'test': test_dir}\n\n# Count and print the number of images in each category for each split\ncategory_counts = {category: {'train': 0, 'val': 0, 'test': 0} for category in categories}\n\nfor split, split_dir in split_directories.items():\n    for category in categories:\n        category_dir = os.path.join(split_dir, category)\n        num_files = len(os.listdir(category_dir))\n        category_counts[category][split] = num_files\n\n# Print the total dataset count for each category\nfor category in categories:\n    total_files = sum(category_counts[category].values())\n    print(f\"Category '{category}': Total files = {total_files}\")\n    print(f\"  Train: {category_counts[category]['train']}\")\n    print(f\"  Validation: {category_counts[category]['val']}\")\n    print(f\"  Test: {category_counts[category]['test']}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:24:11.395210Z","iopub.execute_input":"2024-11-30T14:24:11.395565Z","iopub.status.idle":"2024-11-30T14:24:11.409106Z","shell.execute_reply.started":"2024-11-30T14:24:11.395533Z","shell.execute_reply":"2024-11-30T14:24:11.408056Z"}},"outputs":[{"name":"stdout","text":"Category 'calculus': Total files = 1296\n  Train: 1036\n  Validation: 130\n  Test: 130\nCategory 'caries': Total files = 2382\n  Train: 1905\n  Validation: 238\n  Test: 239\nCategory 'gingivitis': Total files = 2349\n  Train: 1879\n  Validation: 235\n  Test: 235\nCategory 'hypodontia': Total files = 1251\n  Train: 1000\n  Validation: 125\n  Test: 126\nCategory 'tooth_discoloration': Total files = 1834\n  Train: 1467\n  Validation: 183\n  Test: 184\nCategory 'ulcer': Total files = 2541\n  Train: 2032\n  Validation: 254\n  Test: 255\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def build_model(output_classes, learning_rate):\n    base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(DIMX, DIMY, 3))\n    base_model.trainable = False  # Freeze base model\n\n    inputs = Input(shape=(DIMX, DIMY, 3))\n    x = base_model(inputs, training=False)\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(HIDDEN, activation=\"relu\")(x)\n    outputs = Dense(output_classes, activation=\"softmax\")(x)\n\n    model = Model(inputs, outputs)\n    model.compile(optimizer=Adam(learning_rate=learning_rate),\n                  loss=\"categorical_crossentropy\",\n                  metrics=[\"accuracy\"])\n    return model\n    \n# Unfreeze layers and recompile model\ndef unfreeze_base_layers(model, layers, learning_rate):\n    base_model = model.layers[1]  # Base model is the second layer\n    for layer in base_model.layers[-layers:]:\n        layer.trainable = True\n    model.compile(optimizer=Adam(learning_rate=learning_rate),\n                  loss=\"categorical_crossentropy\",\n                  metrics=[\"accuracy\"])\n    return model\n\n# Training the model with gradual fine-tuning\nmodel = build_model(OUTPUT_CLASSES, INITIAL_LEARNING_RATE)\n# Callbacks\ntensorboard_callback = TensorBoard(log_dir=\"./logs\", histogram_freq=1)\nearly_stopping = EarlyStopping(monitor=\"val_loss\", patience=3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:24:14.124541Z","iopub.execute_input":"2024-11-30T14:24:14.125124Z","iopub.status.idle":"2024-11-30T14:24:15.987768Z","shell.execute_reply.started":"2024-11-30T14:24:14.125093Z","shell.execute_reply":"2024-11-30T14:24:15.987107Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Step 1: Train only top layers\nhistory_step1 = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=NUM_FINETUNE_EPOCHS,\n    callbacks=[tensorboard_callback, early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:24:19.455648Z","iopub.execute_input":"2024-11-30T14:24:19.455986Z","iopub.status.idle":"2024-11-30T14:27:51.357011Z","shell.execute_reply.started":"2024-11-30T14:24:19.455955Z","shell.execute_reply":"2024-11-30T14:27:51.356317Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1732976665.015524     188 service.cc:145] XLA service 0x796b6000f5b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1732976665.015597     188 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1732976665.015602     188 service.cc:153]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1732976670.573793     188 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m291/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6683 - loss: 0.8799","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 97ms/step - accuracy: 0.6688 - loss: 0.8782 - val_accuracy: 0.8043 - val_loss: 0.4403\nEpoch 2/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 65ms/step - accuracy: 0.8531 - loss: 0.3600 - val_accuracy: 0.8498 - val_loss: 0.3705\nEpoch 3/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 65ms/step - accuracy: 0.8951 - loss: 0.2592 - val_accuracy: 0.8704 - val_loss: 0.2987\nEpoch 4/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 65ms/step - accuracy: 0.9140 - loss: 0.2098 - val_accuracy: 0.8936 - val_loss: 0.2720\nEpoch 5/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - accuracy: 0.9275 - loss: 0.1826 - val_accuracy: 0.8850 - val_loss: 0.2761\nEpoch 6/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - accuracy: 0.9338 - loss: 0.1534 - val_accuracy: 0.8807 - val_loss: 0.2613\nEpoch 7/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - accuracy: 0.9419 - loss: 0.1349 - val_accuracy: 0.8841 - val_loss: 0.2750\nEpoch 8/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 62ms/step - accuracy: 0.9444 - loss: 0.1270 - val_accuracy: 0.8867 - val_loss: 0.2798\nEpoch 9/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 65ms/step - accuracy: 0.9403 - loss: 0.1253 - val_accuracy: 0.8987 - val_loss: 0.2547\nEpoch 10/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 63ms/step - accuracy: 0.9498 - loss: 0.1175 - val_accuracy: 0.8781 - val_loss: 0.2819\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Evaluate after step 1\nloss, accuracy = model.evaluate(test_generator)\nprint(f\"Step 1 - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:28:28.035618Z","iopub.execute_input":"2024-11-30T14:28:28.035930Z","iopub.status.idle":"2024-11-30T14:28:33.384712Z","shell.execute_reply.started":"2024-11-30T14:28:28.035902Z","shell.execute_reply":"2024-11-30T14:28:33.383880Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - accuracy: 0.8878 - loss: 0.2953\nStep 1 - Loss: 0.2823, Accuracy: 0.8905\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Step 2: Fine-tune more layers\nUNFREEZE_LAYERS = 20  # Number of layers to unfreeze in each step\nlearning_rate = INITIAL_LEARNING_RATE / 10  # Reduce learning rate\nmodel = unfreeze_base_layers(model, layers=UNFREEZE_LAYERS, learning_rate=learning_rate)\n\nhistory_step2 = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=NUM_FINETUNE_EPOCHS,\n    callbacks=[tensorboard_callback, early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:28:34.793877Z","iopub.execute_input":"2024-11-30T14:28:34.794512Z","iopub.status.idle":"2024-11-30T14:29:51.750645Z","shell.execute_reply.started":"2024-11-30T14:28:34.794480Z","shell.execute_reply":"2024-11-30T14:29:51.749780Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 91ms/step - accuracy: 0.8304 - loss: 0.4808 - val_accuracy: 0.8798 - val_loss: 0.3860\nEpoch 2/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 66ms/step - accuracy: 0.9390 - loss: 0.1409 - val_accuracy: 0.8850 - val_loss: 0.3578\nEpoch 3/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 66ms/step - accuracy: 0.9414 - loss: 0.1246 - val_accuracy: 0.9159 - val_loss: 0.2573\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Evaluate after step 2\nloss, accuracy = model.evaluate(test_generator)\nprint(f\"Step 2 - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:32:04.691593Z","iopub.execute_input":"2024-11-30T14:32:04.691960Z","iopub.status.idle":"2024-11-30T14:32:07.932598Z","shell.execute_reply.started":"2024-11-30T14:32:04.691927Z","shell.execute_reply":"2024-11-30T14:32:07.931872Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.8718 - loss: 0.2937\nStep 2 - Loss: 0.3048, Accuracy: 0.8820\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Step 3: Fine-tune deeper layers\nUNFREEZE_LAYERS += 20  # Unfreeze more layers\nlearning_rate /= 2  # Further reduce learning rate\nmodel = unfreeze_base_layers(model, layers=UNFREEZE_LAYERS, learning_rate=learning_rate)\n\nhistory_step3 = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=NUM_FINETUNE_EPOCHS,\n    callbacks=[tensorboard_callback, early_stopping]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:32:09.855775Z","iopub.execute_input":"2024-11-30T14:32:09.856557Z","iopub.status.idle":"2024-11-30T14:35:26.673606Z","shell.execute_reply.started":"2024-11-30T14:32:09.856526Z","shell.execute_reply":"2024-11-30T14:35:26.672886Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 93ms/step - accuracy: 0.9081 - loss: 0.2091 - val_accuracy: 0.8953 - val_loss: 0.3142\nEpoch 2/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 67ms/step - accuracy: 0.9435 - loss: 0.1192 - val_accuracy: 0.9021 - val_loss: 0.2670\nEpoch 3/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - accuracy: 0.9490 - loss: 0.1029 - val_accuracy: 0.9167 - val_loss: 0.2416\nEpoch 4/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 65ms/step - accuracy: 0.9510 - loss: 0.0986 - val_accuracy: 0.9219 - val_loss: 0.2090\nEpoch 5/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 67ms/step - accuracy: 0.9471 - loss: 0.1004 - val_accuracy: 0.9176 - val_loss: 0.2180\nEpoch 6/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 66ms/step - accuracy: 0.9524 - loss: 0.0948 - val_accuracy: 0.9176 - val_loss: 0.2078\nEpoch 7/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - accuracy: 0.9502 - loss: 0.0981 - val_accuracy: 0.8987 - val_loss: 0.2734\nEpoch 8/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 65ms/step - accuracy: 0.9461 - loss: 0.0967 - val_accuracy: 0.9210 - val_loss: 0.2089\nEpoch 9/10\n\u001b[1m292/292\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 64ms/step - accuracy: 0.9521 - loss: 0.0918 - val_accuracy: 0.9116 - val_loss: 0.2357\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Evaluate after step 3\nloss, accuracy = model.evaluate(test_generator)\nprint(f\"Step 3 - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-30T14:51:31.677769Z","iopub.execute_input":"2024-11-30T14:51:31.678372Z","iopub.status.idle":"2024-11-30T14:51:35.176216Z","shell.execute_reply.started":"2024-11-30T14:51:31.678336Z","shell.execute_reply":"2024-11-30T14:51:35.175341Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.8973 - loss: 0.2368\nStep 3 - Loss: 0.2510, Accuracy: 0.8982\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Save final model\nmodel.save(\"fine_tuned_model.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T21:30:01.736060Z","iopub.execute_input":"2024-11-27T21:30:01.736851Z","iopub.status.idle":"2024-11-27T21:30:02.125266Z","shell.execute_reply.started":"2024-11-27T21:30:01.736817Z","shell.execute_reply":"2024-11-27T21:30:02.124501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save final model\nmodel.save(\"fine_tuned_model.h5\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}